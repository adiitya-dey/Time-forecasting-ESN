{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.datasets import AirPassengersDataset, AusBeerDataset, ETTh1Dataset, ETTh2Dataset, ETTm1Dataset, ETTm2Dataset, ExchangeRateDataset, TrafficDataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "from einops import rearrange, repeat, reduce\n",
    "\n",
    "np.random.seed(123)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ESN(nn.Module):\n",
    "\n",
    "    def __init__(self, reservoir_size=100, input_size=1, output_size=1,  spectral_radius=1.0, connectivity_rate=1.0, learning_rate = 0.1, epochs=1, washout=1, activation=\"tanh\"):\n",
    "        super(ESN, self).__init__()\n",
    "        self.reservoir_size = reservoir_size\n",
    "        self.input_size = input_size\n",
    "        self.epochs = epochs\n",
    "        self.connectivity_rate = connectivity_rate\n",
    "        self.spectral_radius = spectral_radius\n",
    "        self.washout = washout\n",
    "        self.output_size = output_size\n",
    "        self.lr = learning_rate\n",
    "        self.activation = self.activation_fn(activation)\n",
    "        \n",
    "\n",
    "        self.state = torch.zeros(self.reservoir_size, 1)\n",
    "        self.W_in = torch.rand((reservoir_size, input_size)) * 2 - 1\n",
    "        \n",
    "        \n",
    "        self.W_out = None\n",
    "\n",
    "        ## Initializing Reservoir Weights according to \"Re-visiting the echo state property\"(2012)\n",
    "        ##\n",
    "        ## Initialize a random matrix and induce sparsity.\n",
    "        self.W_res = torch.rand((reservoir_size, reservoir_size))\n",
    "        self.W_res.data[torch.rand(*self.W_res.shape) > self.connectivity_rate] = 0\n",
    "\n",
    "        ## Scale the matrix based on user defined spectral radius.\n",
    "        current_spectral_radius = torch.max(torch.abs(torch.linalg.eigvals(self.W_res.data)))\n",
    "        self.W_res.data = self.W_res * (self.spectral_radius / current_spectral_radius)\n",
    "\n",
    "        ## Induce half of the weights as negative weights.\n",
    "        total_entries = self.reservoir_size * self.reservoir_size\n",
    "        num_negative_entries = total_entries//2\n",
    "        negative_indices = np.random.choice(total_entries, num_negative_entries, replace=False)\n",
    "        W_flat = self.W_res.data.flatten()\n",
    "        W_flat[negative_indices] *= -1\n",
    "        self.W_res = W_flat.reshape(*self.W_res.shape)\n",
    "\n",
    "\n",
    "        self.all_states = [self.state]\n",
    "\n",
    "    @staticmethod\n",
    "    def activation_fn(x):\n",
    "         \n",
    "        activation_keys = [\"sigmoid\", \"relu\", \"tanh\"]\n",
    "\n",
    "        if x in activation_keys:\n",
    "              if x == \"tanh\":\n",
    "                   return nn.Tanh()\n",
    "              elif x == \"relu\":\n",
    "                   return nn.ReLU()\n",
    "              elif x == \"sigmoid\":\n",
    "                   return nn.Sigmoid()\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(f\"Activation {x} does not exists\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        \n",
    "\n",
    "        state_collection_matrix = torch.zeros(self.input_size + self.reservoir_size, 1)\n",
    "        # self.state = np.zeros((self.reservoir_size, 1))\n",
    "\n",
    "        ## Calculate state of reservoirs per time step\n",
    "        for i in range(X_train.shape[0]-1):\n",
    "            input = X_train[i].reshape(-1,1)\n",
    "            input_product = self.W_in@input\n",
    "            state_product = self.W_res@self.state\n",
    "            self.state = self.activation(input_product + state_product)\n",
    "            state_collection_matrix= torch.hstack((state_collection_matrix, torch.concatenate((self.state, input))))\n",
    "\n",
    "            self.all_states.append(self.state)\n",
    "\n",
    "        ## Update W_out\n",
    "        mat1 = state_collection_matrix.T[self.washout:,:]\n",
    "        X = torch.matmul(mat1.T, mat1)\n",
    "\n",
    "        Y =torch.matmul(mat1.T, y_train[self.washout:,:])\n",
    "\n",
    "        eyes = torch.eye(self.reservoir_size)\n",
    "        print(eyes.shape)\n",
    "\n",
    "        print(X.shape, Y.shape)\n",
    "        self.W_out = torch.matmul(torch.linalg.inv(X + self.lr * eyes, Y))\n",
    "\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "            prediction = np.zeros((self.output_size,1))\n",
    "            for i in range(X_test.shape[0]- 1):\n",
    "                input = X_test[i].reshape(-1,1)\n",
    "                input_product = self.W_in@input\n",
    "                state_product = self.W_res@self.state\n",
    "                self.state = self.activation(input_product + state_product)\n",
    "                concat_matrix= torch.concatenate((self.state, input))\n",
    "                pred =  self.W_out@concat_matrix\n",
    "                prediction = torch.hstack([prediction, pred])\n",
    "\n",
    "                self.all_states.append(self.state)\n",
    "            \n",
    "            prediction = rearrange(prediction, 'c r -> r c')\n",
    "            if self.output_size == self.input_size:\n",
    "                return prediction[1:,:]\n",
    "            else:\n",
    "                return prediction\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_to_uni_datasets = [{\"name\": \"AirPassengers\",\n",
    "             \"dataset\": AirPassengersDataset(),\n",
    "             \"input\": 1,\n",
    "             \"output\": 1},\n",
    "            {\"name\":\"AusBeer\",\n",
    "             \"dataset\": AusBeerDataset(),\n",
    "             \"input\": 1,\n",
    "             \"output\": 1}\n",
    "            ]\n",
    "\n",
    "\n",
    "multi_to_uni_datasets = [{\"name\": \"ETTh1\",\n",
    "                   \"dataset\": ETTh1Dataset(),\n",
    "                   \"input\": 6,\n",
    "                   \"output\": 1},\n",
    "                   {\"name\": \"ETTh2\",\n",
    "                   \"dataset\": ETTh2Dataset(),\n",
    "                   \"input\": 6,\n",
    "                   \"output\": 1},\n",
    "                   {\"name\": \"ETTm1\",\n",
    "                   \"dataset\": ETTm1Dataset(),\n",
    "                   \"input\": 6,\n",
    "                   \"output\": 1},\n",
    "                   {\"name\": \"ETTm2\",\n",
    "                   \"dataset\": ETTm2Dataset(),\n",
    "                   \"input\": 6,\n",
    "                   \"output\": 1}]\n",
    "\n",
    "multi_to_multi_datasets = [{\"name\": \"ETTh1\",\n",
    "                   \"dataset\": ExchangeRateDataset(),\n",
    "                   \"input\": 8,\n",
    "                   \"output\": 8}]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "metrics = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "reservoir_size = 20\n",
    "spectral_radius = 0.7\n",
    "connectivity_rate = 0.8\n",
    "washout = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 20])\n",
      "torch.Size([21, 21]) torch.Size([21, 1])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (21) must match the size of tensor b (20) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m X_test_std \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(sc\u001b[38;5;241m.\u001b[39mtransform(X_test))\n\u001b[1;32m     10\u001b[0m esn \u001b[38;5;241m=\u001b[39m ESN(reservoir_size\u001b[38;5;241m=\u001b[39mreservoir_size, input_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, output_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, spectral_radius\u001b[38;5;241m=\u001b[39mspectral_radius, connectivity_rate\u001b[38;5;241m=\u001b[39mconnectivity_rate, washout\u001b[38;5;241m=\u001b[39mwashout)\n\u001b[0;32m---> 11\u001b[0m \u001b[43mesn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_std\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_std\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[53], line 88\u001b[0m, in \u001b[0;36mESN.fit\u001b[0;34m(self, X_train, y_train)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mprint\u001b[39m(eyes\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mprint\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape, Y\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW_out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39minv(\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43meyes\u001b[49m, Y))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (21) must match the size of tensor b (20) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "data = uni_to_uni_datasets[0][\"dataset\"]\n",
    "time_series = data.load()\n",
    "X = time_series.values()\n",
    "X_train, X_test = train_test_split(X, test_size=test_size, shuffle=False)\n",
    "\n",
    "sc = MinMaxScaler()\n",
    "X_train_std = torch.tensor(sc.fit_transform(X_train))\n",
    "X_test_std = torch.tensor(sc.transform(X_test))\n",
    "\n",
    "esn = ESN(reservoir_size=reservoir_size, input_size=1, output_size=1, spectral_radius=spectral_radius, connectivity_rate=connectivity_rate, washout=washout)\n",
    "esn.fit(X_train_std, X_train_std)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i in uni_to_uni_datasets:\n",
    "    data = i[\"dataset\"]\n",
    "    input_size = i[\"input\"]\n",
    "    output_size = i[\"output\"]\n",
    "    name = i[\"name\"]\n",
    "\n",
    "    time_series = data.load()\n",
    "    X = time_series.values()\n",
    "    X_train, X_test = train_test_split(X, test_size=test_size, shuffle=False)\n",
    "\n",
    "    sc = MinMaxScaler()\n",
    "    X_train_std = sc.fit_transform(X_train)\n",
    "    X_test_std = sc.transform(X_test)\n",
    "\n",
    "\n",
    "    esn = ESN(reservoir_size=reservoir_size, input_size=input_size, output_size=output_size, spectral_radius=spectral_radius, connectivity_rate=connectivity_rate, washout=washout)\n",
    "    esn.fit(X_train_std, X_train_std)\n",
    "\n",
    "    test_values= X_test_std[1:]\n",
    "\n",
    "    predictions = esn.predict(X_test_std)\n",
    "\n",
    "    metrics.append({\"Data\": name,\n",
    "                    \"RMSE\": np.sqrt(mean_squared_error(test_values, predictions)),\n",
    "                    \"MAE\" : mean_absolute_error(test_values, predictions),\n",
    "                    \"MAPE\": mean_absolute_percentage_error(test_values, predictions)       \n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in multi_to_uni_datasets:\n",
    "    data = i[\"dataset\"]\n",
    "    input_size = i[\"input\"]\n",
    "    output_size = i[\"output\"]\n",
    "    name = i[\"name\"]\n",
    "\n",
    "    time_series = data.load().values()\n",
    "    X = time_series[:,:-1]\n",
    "    y = time_series[:,-1]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, shuffle=False)\n",
    "\n",
    "\n",
    "    y_train = rearrange(y_train, 'r -> r 1')\n",
    "    y_test = rearrange(y_test, 'r -> r 1')\n",
    "\n",
    "\n",
    "    sc1 = MinMaxScaler()\n",
    "    X_train_std = sc1.fit_transform(X_train)\n",
    "    X_test_std = sc1.transform(X_test)\n",
    "\n",
    "    sc2 = MinMaxScaler()\n",
    "    y_train_std = sc2.fit_transform(y_train)\n",
    "    y_test_std = sc2.transform(y_test)\n",
    "    \n",
    "\n",
    "    esn = ESN(reservoir_size=reservoir_size, input_size=input_size, output_size=output_size, spectral_radius=spectral_radius, connectivity_rate=connectivity_rate, washout=washout)\n",
    "    esn.fit(X_train_std, y_train_std)\n",
    "\n",
    "    predictions = esn.predict2(X_test_std)\n",
    "\n",
    "    metrics.append({\"Data\": name,\n",
    "                    \"RMSE\": np.sqrt(mean_squared_error(y_test_std, predictions)),\n",
    "                    \"MAE\" : mean_absolute_error(y_test_std, predictions),\n",
    "                    \"MAPE\": mean_absolute_percentage_error(y_test_std, predictions)       \n",
    "                    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [13936, 1517]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 24\u001b[0m\n\u001b[1;32m     19\u001b[0m test_values\u001b[38;5;241m=\u001b[39m X_test_std[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m     21\u001b[0m predictions \u001b[38;5;241m=\u001b[39m esn\u001b[38;5;241m.\u001b[39mpredict(X_test_std)\n\u001b[1;32m     23\u001b[0m metrics\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData\u001b[39m\u001b[38;5;124m\"\u001b[39m: name,\n\u001b[0;32m---> 24\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRMSE\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39msqrt(\u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test_std\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m),\n\u001b[1;32m     25\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMAE\u001b[39m\u001b[38;5;124m\"\u001b[39m : mean_absolute_error(y_test_std, predictions),\n\u001b[1;32m     26\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMAPE\u001b[39m\u001b[38;5;124m\"\u001b[39m: mean_absolute_percentage_error(y_test_std, predictions)       \n\u001b[1;32m     27\u001b[0m                 })\n",
      "File \u001b[0;32m~/Documents/Time-forecasting-ESN/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Time-forecasting-ESN/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py:497\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m squared:\n\u001b[1;32m    493\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m root_mean_squared_error(\n\u001b[1;32m    494\u001b[0m             y_true, y_pred, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, multioutput\u001b[38;5;241m=\u001b[39mmultioutput\n\u001b[1;32m    495\u001b[0m         )\n\u001b[0;32m--> 497\u001b[0m y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    501\u001b[0m output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage((y_true \u001b[38;5;241m-\u001b[39m y_pred) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, weights\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[0;32m~/Documents/Time-forecasting-ESN/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py:102\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_reg_targets\u001b[39m(y_true, y_pred, multioutput, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     69\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m        correct keyword.\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    104\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/Documents/Time-forecasting-ESN/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:430\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    428\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 430\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    431\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    432\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    433\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [13936, 1517]"
     ]
    }
   ],
   "source": [
    "for i in multi_to_multi_datasets:\n",
    "    data = i[\"dataset\"]\n",
    "    input_size = i[\"input\"]\n",
    "    output_size = i[\"output\"]\n",
    "    name = i[\"name\"]\n",
    "\n",
    "    time_series = data.load()\n",
    "    X = time_series.values()\n",
    "    X_train, X_test = train_test_split(X, test_size=test_size, shuffle=False)\n",
    "\n",
    "    sc = MinMaxScaler()\n",
    "    X_train_std = sc.fit_transform(X_train)\n",
    "    X_test_std = sc.transform(X_test)\n",
    "\n",
    "\n",
    "    esn = ESN(reservoir_size=reservoir_size, input_size=input_size, output_size=output_size, spectral_radius=spectral_radius, connectivity_rate=connectivity_rate, washout=washout)\n",
    "    esn.fit(X_train_std, X_train_std)\n",
    "\n",
    "    test_values= X_test_std[1:]\n",
    "\n",
    "    predictions = esn.predict(X_test_std)\n",
    "\n",
    "    metrics.append({\"Data\": name,\n",
    "                    \"RMSE\": np.sqrt(mean_squared_error(y_test_std, predictions)),\n",
    "                    \"MAE\" : mean_absolute_error(y_test_std, predictions),\n",
    "                    \"MAPE\": mean_absolute_percentage_error(y_test_std, predictions)       \n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(metrics)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
