{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.datasets import AirPassengersDataset, AusBeerDataset, ETTh1Dataset, ETTh2Dataset, ETTm1Dataset, ETTm2Dataset, ExchangeRateDataset, TrafficDataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "from einops import rearrange, repeat, reduce\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESN(BaseEstimator):\n",
    "\n",
    "    def __init__(self, reservoir_size=100, input_size=1, output_size=1,  spectral_radius=1.0, connectivity_rate=1.0, epochs=1, lr=0.01, leaky_parameter=1.0, washout=1):\n",
    "        self.reservoir_size = reservoir_size\n",
    "        self.input_size = input_size\n",
    "        self.epochs = epochs\n",
    "        self.connectivity_rate = connectivity_rate\n",
    "        self.lr = lr\n",
    "        self.spectral_radius = spectral_radius\n",
    "        self.washout = washout\n",
    "        self.leaky_parameter = leaky_parameter\n",
    "        self.output_size = output_size\n",
    "        \n",
    "\n",
    "        self.state = np.zeros((self.reservoir_size, 1))\n",
    "        self.W_in = np.random.rand(reservoir_size, input_size) * 2 - 1\n",
    "        self.W_in, _ = np.linalg.qr(self.W_in)\n",
    "        \n",
    "        self.W_out = None\n",
    "\n",
    "        # ## Initializing Reservoir Weights according to original paper(2001).\n",
    "        # ##\n",
    "        # ## Initialize a random matrix and induce sparsity \n",
    "        # self.W_res = np.random.randn(reservoir_size, reservoir_size)\n",
    "        # self.W_res[np.random.rand(*self.W_res.shape) > self.connectivity_rate] = 0\n",
    "\n",
    "        # ##  Scale the matrix based on user defined spectral radius.\n",
    "        # current_spectral_radius = np.max(np.abs(np.linalg.eigvals(self.W_res)))\n",
    "        # self.W_res = self.W_res * (self.spectral_radius / current_spectral_radius)\n",
    "\n",
    "\n",
    "        ## Initializing Reservoir Weights according to \"Re-visiting the echo state property\"(2012)\n",
    "        ##\n",
    "        ## Initialize a random matrix and induce sparsity.\n",
    "        self.W_res = np.random.rand(reservoir_size, reservoir_size)\n",
    "        self.W_res[np.random.rand(*self.W_res.shape) > self.connectivity_rate] = 0\n",
    "\n",
    "        ## Scale the matrix based on user defined spectral radius.\n",
    "        current_spectral_radius = np.max(np.abs(np.linalg.eigvals(self.W_res)))\n",
    "        self.W_res = self.W_res * (self.spectral_radius / current_spectral_radius)\n",
    "\n",
    "        ## Induce half of the weights as negative weights.\n",
    "        total_entries = self.W_res.size\n",
    "        num_negative_entries = total_entries//2\n",
    "        negative_indices = np.random.choice(total_entries, num_negative_entries, replace=False)\n",
    "        W_flat = self.W_res.flatten()\n",
    "        W_flat[negative_indices] *= -1\n",
    "        self.W_res = W_flat.reshape(self.W_res.shape)\n",
    "\n",
    "\n",
    "        self.all_states = [self.state]\n",
    "\n",
    "    @staticmethod\n",
    "    def activation(x):\n",
    "         \n",
    "        ## Hyperbolic Tangent Function\n",
    "         return np.tanh(x)\n",
    "\n",
    "        # ## ReLU Fuction\n",
    "        # return np.clip(x, 0, np.inf)\n",
    "    \n",
    "        # ## Sigmoid Function\n",
    "        # return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "    def fit(self, X_train, y_train=None):\n",
    "        \n",
    "        ## Epochs are useless. Keep it as 1 always.\n",
    "        for _ in range(self.epochs): \n",
    "\n",
    "            ## Reset states.\n",
    "            state_collection_matrix = np.zeros((self.input_size + self.reservoir_size, 1))\n",
    "            # self.state = np.zeros((self.reservoir_size, 1))\n",
    "\n",
    "            ## Calculate state of reservoirs per time step\n",
    "            for i in range(X_train.shape[0]-1):\n",
    "\n",
    "               \n",
    "\n",
    "                input = X_train[i].reshape(-1,1)\n",
    "                input_product = self.W_in@input\n",
    "                state_product = self.W_res@self.state\n",
    "                self.state = self.activation(input_product + state_product)\n",
    "                state_collection_matrix= np.hstack((state_collection_matrix, np.concatenate((self.state, input))))\n",
    "\n",
    "                self.all_states.append(self.state)\n",
    "\n",
    "            ## Update W_out\n",
    "            mat1 = state_collection_matrix.T[self.washout:,:]\n",
    "            ridge_regressor= Ridge(alpha=self.lr)\n",
    "            ridge_regressor.fit(mat1, y_train[self.washout:,:])\n",
    "            self.W_out = ridge_regressor.coef_\n",
    "            # self.W_out = np.dot(np.linalg.pinv(mat1), y_train)\n",
    "\n",
    "\n",
    "    # def predict(self, X_test):\n",
    "    #         input_product = self.W_in@X_test\n",
    "    #         state_product = self.W_res@self.state\n",
    "    #         self.state = np.tanh(input_product + state_product)\n",
    "    #         concat_matrix= np.concatenate((self.state, X_test))\n",
    "    #         pred =  self.W_out@concat_matrix\n",
    "    #         return pred\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "            prediction = np.zeros((self.output_size,1))\n",
    "            for i in range(X_test.shape[0]- 1):\n",
    "                input = X_test[i].reshape(-1,1)\n",
    "                input_product = self.W_in@input\n",
    "                state_product = self.W_res@self.state\n",
    "                self.state = self.activation(input_product + state_product)\n",
    "                concat_matrix= np.concatenate((self.state, input))\n",
    "                pred =  self.W_out@concat_matrix\n",
    "                prediction = np.hstack([prediction, pred])\n",
    "\n",
    "                self.all_states.append(self.state)\n",
    "            \n",
    "            prediction = rearrange(prediction, 'c r -> r c')\n",
    "            return prediction[1:,:]\n",
    "    \n",
    "\n",
    "    def predict2(self, X_test):\n",
    "            prediction = np.zeros((1,1))\n",
    "            for i in range(X_test.shape[0]- 1):\n",
    "                input = X_test[i].reshape(-1,1)\n",
    "                input_product = self.W_in@input\n",
    "                state_product = self.W_res@self.state\n",
    "                self.state = self.activation(input_product + state_product)\n",
    "                concat_matrix= np.concatenate((self.state, input))\n",
    "                pred =  self.W_out@concat_matrix\n",
    "                prediction = np.hstack([prediction, pred])\n",
    "\n",
    "                self.all_states.append(self.state)\n",
    "            \n",
    "            prediction = rearrange(prediction, 'c r -> r c')\n",
    "            return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_to_uni_datasets = [{\"name\": \"AirPassengers\",\n",
    "             \"dataset\": AirPassengersDataset(),\n",
    "             \"input\": 1,\n",
    "             \"output\": 1},\n",
    "            {\"name\":\"AusBeer\",\n",
    "             \"dataset\": AusBeerDataset(),\n",
    "             \"input\": 1,\n",
    "             \"output\": 1}\n",
    "            ]\n",
    "\n",
    "\n",
    "multi_to_uni_datasets = [{\"name\": \"ETTh1\",\n",
    "                   \"dataset\": ETTh1Dataset(),\n",
    "                   \"input\": 6,\n",
    "                   \"output\": 1},\n",
    "                   {\"name\": \"ETTh2\",\n",
    "                   \"dataset\": ETTh2Dataset(),\n",
    "                   \"input\": 6,\n",
    "                   \"output\": 1},\n",
    "                   {\"name\": \"ETTm1\",\n",
    "                   \"dataset\": ETTm1Dataset(),\n",
    "                   \"input\": 6,\n",
    "                   \"output\": 1},\n",
    "                   {\"name\": \"ETTm2\",\n",
    "                   \"dataset\": ETTm2Dataset(),\n",
    "                   \"input\": 6,\n",
    "                   \"output\": 1}]\n",
    "\n",
    "multi_to_multi_datasets = [{\"name\": \"ETTh1\",\n",
    "                   \"dataset\": ExchangeRateDataset(),\n",
    "                   \"input\": 8,\n",
    "                   \"output\": 8}]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "metrics = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "reservoir_size = 20\n",
    "spectral_radius = 0.7\n",
    "connectivity_rate = 0.8\n",
    "washout = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i in uni_to_uni_datasets:\n",
    "    data = i[\"dataset\"]\n",
    "    input_size = i[\"input\"]\n",
    "    output_size = i[\"output\"]\n",
    "    name = i[\"name\"]\n",
    "\n",
    "    time_series = data.load()\n",
    "    X = time_series.values()\n",
    "    X_train, X_test = train_test_split(X, test_size=test_size, shuffle=False)\n",
    "\n",
    "    sc = MinMaxScaler()\n",
    "    X_train_std = sc.fit_transform(X_train)\n",
    "    X_test_std = sc.transform(X_test)\n",
    "\n",
    "\n",
    "    esn = ESN(reservoir_size=reservoir_size, input_size=input_size, output_size=output_size, spectral_radius=spectral_radius, connectivity_rate=connectivity_rate, washout=washout)\n",
    "    esn.fit(X_train_std, X_train_std)\n",
    "\n",
    "    test_values= X_test_std[1:]\n",
    "\n",
    "    predictions = esn.predict(X_test_std)\n",
    "\n",
    "    metrics.append({\"Data\": name,\n",
    "                    \"RMSE\": np.sqrt(mean_squared_error(test_values, predictions)),\n",
    "                    \"MAE\" : mean_absolute_error(test_values, predictions),\n",
    "                    \"MAPE\": mean_absolute_percentage_error(test_values, predictions)       \n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in multi_to_uni_datasets:\n",
    "    data = i[\"dataset\"]\n",
    "    input_size = i[\"input\"]\n",
    "    output_size = i[\"output\"]\n",
    "    name = i[\"name\"]\n",
    "\n",
    "    time_series = data.load().values()\n",
    "    X = time_series[:,:-1]\n",
    "    y = time_series[:,-1]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, shuffle=False)\n",
    "\n",
    "\n",
    "    y_train = rearrange(y_train, 'r -> r 1')\n",
    "    y_test = rearrange(y_test, 'r -> r 1')\n",
    "\n",
    "\n",
    "    sc1 = MinMaxScaler()\n",
    "    X_train_std = sc1.fit_transform(X_train)\n",
    "    X_test_std = sc1.transform(X_test)\n",
    "\n",
    "    sc2 = MinMaxScaler()\n",
    "    y_train_std = sc2.fit_transform(y_train)\n",
    "    y_test_std = sc2.transform(y_test)\n",
    "    \n",
    "\n",
    "    esn = ESN(reservoir_size=reservoir_size, input_size=input_size, output_size=output_size, spectral_radius=spectral_radius, connectivity_rate=connectivity_rate, washout=washout)\n",
    "    esn.fit(X_train_std, y_train_std)\n",
    "\n",
    "    predictions = esn.predict2(X_test_std)\n",
    "\n",
    "    metrics.append({\"Data\": name,\n",
    "                    \"RMSE\": np.sqrt(mean_squared_error(y_test_std, predictions)),\n",
    "                    \"MAE\" : mean_absolute_error(y_test_std, predictions),\n",
    "                    \"MAPE\": mean_absolute_percentage_error(y_test_std, predictions)       \n",
    "                    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [13936, 1517]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 24\u001b[0m\n\u001b[1;32m     19\u001b[0m test_values\u001b[38;5;241m=\u001b[39m X_test_std[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m     21\u001b[0m predictions \u001b[38;5;241m=\u001b[39m esn\u001b[38;5;241m.\u001b[39mpredict(X_test_std)\n\u001b[1;32m     23\u001b[0m metrics\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData\u001b[39m\u001b[38;5;124m\"\u001b[39m: name,\n\u001b[0;32m---> 24\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRMSE\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39msqrt(\u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test_std\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m),\n\u001b[1;32m     25\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMAE\u001b[39m\u001b[38;5;124m\"\u001b[39m : mean_absolute_error(y_test_std, predictions),\n\u001b[1;32m     26\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMAPE\u001b[39m\u001b[38;5;124m\"\u001b[39m: mean_absolute_percentage_error(y_test_std, predictions)       \n\u001b[1;32m     27\u001b[0m                 })\n",
      "File \u001b[0;32m~/Documents/Time-forecasting-ESN/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Time-forecasting-ESN/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py:497\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m squared:\n\u001b[1;32m    493\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m root_mean_squared_error(\n\u001b[1;32m    494\u001b[0m             y_true, y_pred, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, multioutput\u001b[38;5;241m=\u001b[39mmultioutput\n\u001b[1;32m    495\u001b[0m         )\n\u001b[0;32m--> 497\u001b[0m y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    501\u001b[0m output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage((y_true \u001b[38;5;241m-\u001b[39m y_pred) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, weights\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[0;32m~/Documents/Time-forecasting-ESN/.venv/lib/python3.10/site-packages/sklearn/metrics/_regression.py:102\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_reg_targets\u001b[39m(y_true, y_pred, multioutput, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     69\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m        correct keyword.\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    104\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/Documents/Time-forecasting-ESN/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:430\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    428\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 430\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    431\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    432\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    433\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [13936, 1517]"
     ]
    }
   ],
   "source": [
    "for i in multi_to_multi_datasets:\n",
    "    data = i[\"dataset\"]\n",
    "    input_size = i[\"input\"]\n",
    "    output_size = i[\"output\"]\n",
    "    name = i[\"name\"]\n",
    "\n",
    "    time_series = data.load()\n",
    "    X = time_series.values()\n",
    "    X_train, X_test = train_test_split(X, test_size=test_size, shuffle=False)\n",
    "\n",
    "    sc = MinMaxScaler()\n",
    "    X_train_std = sc.fit_transform(X_train)\n",
    "    X_test_std = sc.transform(X_test)\n",
    "\n",
    "\n",
    "    esn = ESN(reservoir_size=reservoir_size, input_size=input_size, output_size=output_size, spectral_radius=spectral_radius, connectivity_rate=connectivity_rate, washout=washout)\n",
    "    esn.fit(X_train_std, X_train_std)\n",
    "\n",
    "    test_values= X_test_std[1:]\n",
    "\n",
    "    predictions = esn.predict(X_test_std)\n",
    "\n",
    "    metrics.append({\"Data\": name,\n",
    "                    \"RMSE\": np.sqrt(mean_squared_error(y_test_std, predictions)),\n",
    "                    \"MAE\" : mean_absolute_error(y_test_std, predictions),\n",
    "                    \"MAPE\": mean_absolute_percentage_error(y_test_std, predictions)       \n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(metrics)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
